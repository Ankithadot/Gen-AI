{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üîç Code Explanation ‚Äì Step by Step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 1: Dataset Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These are the essential libraries:\n",
        "\n",
        "pandas and numpy: for data manipulation\n",
        "\n",
        "re and string: for text cleaning\n",
        "\n",
        "matplotlib: for optional data visualization\n",
        "\n",
        "train_test_split: to divide data into training and testing sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "news_df = pd.read_csv(\"news_summary.csv\", encoding='latin-1')\n",
        "news_df = news_df[['text', 'headlines']].dropna()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the CSV dataset.\n",
        "\n",
        "Use only the relevant columns: text (news body) and headlines (titles).\n",
        "\n",
        "Drop rows with missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xgr8FDC0riFz",
        "outputId": "fc38f58d-89f5-4cc3-88d8-8bec8aca7da8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text  \\\n",
            "0  The Administration of Union Territory Daman an...   \n",
            "1  Malaika Arora slammed an Instagram user who tr...   \n",
            "2  The Indira Gandhi Institute of Medical Science...   \n",
            "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...   \n",
            "4  Hotels in Maharashtra will train their staff t...   \n",
            "\n",
            "                                           headlines  \n",
            "0  Daman & Diu revokes mandatory Rakshabandhan in...  \n",
            "1  Malaika slams user who trolled her for 'divorc...  \n",
            "2  'Virgin' now corrected to 'Unmarried' in IGIMS...  \n",
            "3  Aaj aapne pakad liya: LeT man Dujana before be...  \n",
            "4  Hotel staff to get training to spot signs of s...  \n"
          ]
        }
      ],
      "source": [
        "# Auto Headline Generator ‚Äì Using LSTM & GRU\n",
        "\n",
        "# Step 1: Dataset Collection\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "news_df = pd.read_csv(\"/content/news_summary.csv.zip\", encoding='latin-1')\n",
        "news_df = news_df[['text', 'headlines']].dropna()\n",
        "\n",
        "# Display a few rows\n",
        "print(news_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 2: Data Preprocessing\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(\"\\([^)]*\\)\", \"\", text)\n",
        "    text = re.sub(\"\\d\", \"\", text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub(\"\\s+\", \" \", text)\n",
        "    return text.strip()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A function that:\n",
        "\n",
        "Converts text to lowercase\n",
        "\n",
        "Removes digits and punctuation\n",
        "\n",
        "Cleans up extra spaces\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "news_df['clean_text'] = news_df['text'].apply(clean_text)\n",
        "news_df['clean_headlines'] = news_df['headlines'].apply(clean_text)\n",
        "news_df['decoder_input'] = '<sos> ' + news_df['clean_headlines']\n",
        "news_df['decoder_target'] = news_df['clean_headlines'] + ' <eos>'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apply the cleaning function\n",
        "\n",
        "Add special tokens <sos> (start of sequence) and <eos> (end of sequence) for sequence generation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aVVx1al1sNQH"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 2: Data Preprocessing\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(\"\\([^)]*\\)\", \"\", text)\n",
        "    text = re.sub(\"\\d\", \"\", text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub(\"\\s+\", \" \", text)\n",
        "    return text.strip()\n",
        "\n",
        "news_df['clean_text'] = news_df['text'].apply(clean_text)\n",
        "news_df['clean_headlines'] = news_df['headlines'].apply(clean_text)\n",
        "\n",
        "# Add start and end tokens for decoder\n",
        "news_df['decoder_input'] = '<sos> ' + news_df['clean_headlines']\n",
        "news_df['decoder_target'] = news_df['clean_headlines'] + ' <eos>'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 3: Tokenization and Padding\n",
        "\n",
        "\n",
        "Converts words to integers using top 10,000 frequent words\n",
        "\n",
        "<OOV> handles out-of-vocab words\n",
        "\n",
        "Transforms and pads text sequences to fixed length (50)\n",
        "\n",
        "Tokenizer for decoder input (headlines)\n",
        "\n",
        "Pad both input and target sequences for training the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2cdkezsBsYLy"
      },
      "outputs": [],
      "source": [
        "# Step 3: Tokenization and Padding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "num_words = 10000\n",
        "max_text_len = 50\n",
        "max_headline_len = 15\n",
        "\n",
        "text_tokenizer = Tokenizer(num_words=num_words, oov_token=\"<OOV>\")\n",
        "text_tokenizer.fit_on_texts(news_df['clean_text'])\n",
        "text_seq = text_tokenizer.texts_to_sequences(news_df['clean_text'])\n",
        "text_pad = pad_sequences(text_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "headline_tokenizer = Tokenizer(num_words=num_words, oov_token=\"<OOV>\")\n",
        "headline_tokenizer.fit_on_texts(news_df['decoder_input'])\n",
        "decoder_input_seq = headline_tokenizer.texts_to_sequences(news_df['decoder_input'])\n",
        "decoder_input_pad = pad_sequences(decoder_input_seq, maxlen=max_headline_len, padding='post')\n",
        "\n",
        "decoder_target_seq = headline_tokenizer.texts_to_sequences(news_df['decoder_target'])\n",
        "decoder_target_pad = pad_sequences(decoder_target_seq, maxlen=max_headline_len, padding='post')\n",
        "\n",
        "# Save tokenizer\n",
        "import pickle\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump({'text': text_tokenizer, 'headline': headline_tokenizer}, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 4: Train-Test Split\n",
        "\n",
        "90% training and 10% test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "b7VBfPS2tGI-"
      },
      "outputs": [],
      "source": [
        "# Step 4: Train-Test Split\n",
        "x_train, x_test, y_train_in, y_test_in, y_train_out, y_test_out = train_test_split(\n",
        "    text_pad, decoder_input_pad, decoder_target_pad, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 5 & 6: Model Building and Training (LSTM & GRU)\n",
        "\n",
        "Encoder: Embedding layer + LSTM which outputs hidden state h and cell state c\n",
        "\n",
        "Decoder: Uses the states from the encoder to generate a sequence\n",
        "\n",
        "Output layer with softmax to classify each time step word\n",
        "\n",
        "GRU (same logic, fewer parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "dfL4eWsGtMwk",
        "outputId": "99acc089-176f-4479-dd2c-1d72194465be"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)        </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape      </span>‚îÉ<span style=\"font-weight: bold\">    Param # </span>‚îÉ<span style=\"font-weight: bold\"> Connected to      </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ input_layer         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ -                 ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ input_layer_1       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ -                 ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ embedding           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   ‚îÇ  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> ‚îÇ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ embedding_1         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   ‚îÇ  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> ‚îÇ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         ‚îÇ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>),     ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> ‚îÇ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   ‚îÇ\n",
              "‚îÇ                     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>),      ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îÇ                     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)]      ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> ‚îÇ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
              "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       ‚îÇ\n",
              "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>) ‚îÇ  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010,000</span> ‚îÇ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ input_layer         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ -                 ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mInputLayer\u001b[0m)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ input_layer_1       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ -                 ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mInputLayer\u001b[0m)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ embedding           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m100\u001b[0m)   ‚îÇ  \u001b[38;5;34m1,000,000\u001b[0m ‚îÇ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ embedding_1         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m100\u001b[0m)   ‚îÇ  \u001b[38;5;34m1,000,000\u001b[0m ‚îÇ input_layer_1[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm (\u001b[38;5;33mLSTM\u001b[0m)         ‚îÇ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m),     ‚îÇ     \u001b[38;5;34m80,400\u001b[0m ‚îÇ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   ‚îÇ\n",
              "‚îÇ                     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m),      ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îÇ                     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)]      ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m100\u001b[0m)   ‚îÇ     \u001b[38;5;34m80,400\u001b[0m ‚îÇ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
              "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       ‚îÇ\n",
              "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m10000\u001b[0m) ‚îÇ  \u001b[38;5;34m1,010,000\u001b[0m ‚îÇ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,170,800</span> (12.10 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,170,800\u001b[0m (12.10 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,170,800</span> (12.10 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,170,800\u001b[0m (12.10 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Step 5: Model Building (LSTM)\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, GRU, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "embed_dim = 100\n",
        "\n",
        "# LSTM Model\n",
        "text_input = Input(shape=(max_text_len,))\n",
        "embedding_text = Embedding(num_words, embed_dim)(text_input)\n",
        "encoder_lstm = LSTM(100, return_state=True)\n",
        "_, h, c = encoder_lstm(embedding_text)\n",
        "\n",
        "decoder_input = Input(shape=(max_headline_len,))\n",
        "embedding_headline = Embedding(num_words, embed_dim)(decoder_input)\n",
        "decoder_lstm = LSTM(100, return_sequences=True)(embedding_headline, initial_state=[h, c])\n",
        "output = Dense(num_words, activation='softmax')(decoder_lstm)\n",
        "\n",
        "lstm_model = Model([text_input, decoder_input], output)\n",
        "lstm_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "lstm_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiUZUGDWtWFg",
        "outputId": "1d05a288-4e21-4927-995c-56007781a519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - loss: 8.9056 - val_loss: 6.6746\n",
            "Epoch 2/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - loss: 6.0772 - val_loss: 5.4696\n",
            "Epoch 3/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - loss: 5.1838 - val_loss: 5.2304\n",
            "Epoch 4/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - loss: 4.9786 - val_loss: 5.1460\n",
            "Epoch 5/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - loss: 4.8770 - val_loss: 5.0918\n",
            "Epoch 6/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - loss: 4.8061 - val_loss: 5.0468\n",
            "Epoch 7/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - loss: 4.7362 - val_loss: 5.0106\n",
            "Epoch 8/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - loss: 4.6606 - val_loss: 4.9852\n",
            "Epoch 9/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - loss: 4.6253 - val_loss: 4.9751\n",
            "Epoch 10/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - loss: 4.5862 - val_loss: 4.9678\n",
            "Epoch 11/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - loss: 4.5440 - val_loss: 4.9590\n",
            "Epoch 12/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - loss: 4.4747 - val_loss: 4.9654\n",
            "Epoch 13/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.4777 - val_loss: 4.9668\n",
            "Epoch 14/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - loss: 4.4135 - val_loss: 4.9784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Step 6: Model Training (LSTM)\n",
        "es = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "lstm_model.fit([x_train, y_train_in], y_train_out.reshape(*y_train_out.shape, 1),\n",
        "               epochs=30, batch_size=128,\n",
        "               validation_split=0.1,\n",
        "               callbacks=[es])\n",
        "\n",
        "# Save the LSTM model\n",
        "lstm_model.save('headline_lstm_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 7: Save Models\n",
        "\n",
        "Save trained models for later use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "id": "ZpGGdQR2v7qD",
        "outputId": "8f88b708-e050-4dd1-f4d7-6741ef255446"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)        </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape      </span>‚îÉ<span style=\"font-weight: bold\">    Param # </span>‚îÉ<span style=\"font-weight: bold\"> Connected to      </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ input_layer         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ -                 ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ input_layer_1       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ -                 ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ embedding           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   ‚îÇ  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> ‚îÇ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ embedding_1         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   ‚îÇ  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> ‚îÇ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)           ‚îÇ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>),     ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">60,600</span> ‚îÇ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   ‚îÇ\n",
              "‚îÇ                     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)]      ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">60,600</span> ‚îÇ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
              "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ gru[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]         ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>) ‚îÇ  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010,000</span> ‚îÇ gru_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ input_layer         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ -                 ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mInputLayer\u001b[0m)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ input_layer_1       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ -                 ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mInputLayer\u001b[0m)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ embedding           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m100\u001b[0m)   ‚îÇ  \u001b[38;5;34m1,000,000\u001b[0m ‚îÇ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ embedding_1         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m100\u001b[0m)   ‚îÇ  \u001b[38;5;34m1,000,000\u001b[0m ‚îÇ input_layer_1[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ gru (\u001b[38;5;33mGRU\u001b[0m)           ‚îÇ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m),     ‚îÇ     \u001b[38;5;34m60,600\u001b[0m ‚îÇ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   ‚îÇ\n",
              "‚îÇ                     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)]      ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ gru_1 (\u001b[38;5;33mGRU\u001b[0m)         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m100\u001b[0m)   ‚îÇ     \u001b[38;5;34m60,600\u001b[0m ‚îÇ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
              "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ gru[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m]         ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_1 (\u001b[38;5;33mDense\u001b[0m)     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m10000\u001b[0m) ‚îÇ  \u001b[38;5;34m1,010,000\u001b[0m ‚îÇ gru_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,131,200</span> (11.94 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,131,200\u001b[0m (11.94 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,131,200</span> (11.94 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,131,200\u001b[0m (11.94 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 1s/step - loss: 8.7258 - val_loss: 6.5035\n",
            "Epoch 2/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - loss: 5.9726 - val_loss: 5.4335\n",
            "Epoch 3/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - loss: 5.1392 - val_loss: 5.1562\n",
            "Epoch 4/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.8862 - val_loss: 5.0526\n",
            "Epoch 5/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - loss: 4.7576 - val_loss: 5.0062\n",
            "Epoch 6/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - loss: 4.6561 - val_loss: 4.9790\n",
            "Epoch 7/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - loss: 4.5739 - val_loss: 4.9611\n",
            "Epoch 8/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - loss: 4.5245 - val_loss: 4.9475\n",
            "Epoch 9/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - loss: 4.4452 - val_loss: 4.9381\n",
            "Epoch 10/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - loss: 4.3978 - val_loss: 4.9367\n",
            "Epoch 11/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 1s/step - loss: 4.3412 - val_loss: 4.9406\n",
            "Epoch 12/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.2822 - val_loss: 4.9568\n",
            "Epoch 13/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - loss: 4.2448 - val_loss: 4.9617\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Step 7: GRU Model\n",
        "encoder_gru = GRU(100, return_state=True)\n",
        "_, h_gru = encoder_gru(embedding_text)\n",
        "\n",
        "decoder_gru_layer = GRU(100, return_sequences=True)\n",
        "decoder_gru_output = decoder_gru_layer(embedding_headline, initial_state=[h_gru])\n",
        "output_gru = Dense(num_words, activation='softmax')(decoder_gru_output)\n",
        "\n",
        "gru_model = Model([text_input, decoder_input], output_gru)\n",
        "gru_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "gru_model.summary()\n",
        "\n",
        "gru_model.fit([x_train, y_train_in], y_train_out.reshape(*y_train_out.shape, 1),\n",
        "              epochs=30, batch_size=128,\n",
        "              validation_split=0.1,\n",
        "              callbacks=[es])\n",
        "\n",
        "# Save the GRU model\n",
        "gru_model.save('headline_gru_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 8: Headline Generation Functions\n",
        "\n",
        "decode_sequence_argmax(): picks the most likely word at each step\n",
        "\n",
        "decode_sequence_topk(): randomly picks from top K likely words to create variety"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POZx1-IB0Ucl",
        "outputId": "b0d86255-ce4b-42a1-c145-087b21f50c40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Text: malaika arora slammed an instagram user who trolled her for divorcing a rich man and having fun with the alimony her life now is all about wearing short clothes going to gym or salon enjoying vacations the user commented malaika responded you certainly got to get your damn facts right before spewing sht on mewhen you know nothing about me\n",
            "LSTM Headline: post says at years post study ban trump ganguly against study over of on yrs\n",
            "GRU Headline: ban at him <OOV> to ban govt assembly kejriwal over by says says him remark\n",
            "Input Text: the indira gandhi institute of medical sciences in patna on thursday made corrections in its marital declaration form by changing virgin option to unmarried earlier bihar health minister defined virgin as being an unmarried woman and did not consider the term objectionable the institute however faced strong backlash for asking new recruits to declare their virginity in the form\n",
            "LSTM Headline: airport\n",
            "GRU Headline: post of for on as reports report study out airport over us ganguly him from\n",
            "Input Text: lashkaretaibas kashmir commander abu dujana who was killed by security forces said kabhi hum aage kabhi aap aaj aapne pakad liya mubarak ho aapko after being caught he added that he wont surrender and whatever is in his fate will happen to him hum nikley they shaheed hone he added\n",
            "LSTM Headline: pm on kejriwal sc says from of on trump up over pm case ban pm\n",
            "GRU Headline: film on him ganguly ban bjp kejriwal govt case chief home remark arrested of poor\n",
            "Input Text: hotels in maharashtra will train their staff to spot signs of sex trafficking including frequent requests for bed linen changes and do not disturb signs left on room doors for days a mobile phone app called rescue me which will allow staff to alert police of suspicious behaviour will be developed the initiative has been backed by the maharashtra government\n",
            "LSTM Headline: ban years india airport reports arrested to for delhi him kejriwal airport cm cm sc\n",
            "GRU Headline: govt of us assembly report by hc\n",
            "Input Text: a yearold man on wednesday was found hanging inside the washroom of a delhi police station after he was called for interrogation his family alleged that he could have been emotionally and physically tortured police said the man was named as a suspect in the kidnapping case of a married woman with whom he had been in a relationship earlier\n",
            "LSTM Headline: airport years <OOV> to kejriwal mp a a for india study report cm on study\n",
            "GRU Headline: of minister kejriwal chief chief minister govt ban with case by after\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def decode_sequence(model, input_seq, tokenizer, max_len, start_token=\"<sos>\", end_token=\"<eos>\", temperature=1.0, top_k=50):\n",
        "    # Prepare the input sequence\n",
        "    encoded_input_seq = pad_sequences(tokenizer.texts_to_sequences([input_seq]), maxlen=max_text_len, padding='post')\n",
        "    target_seq = tokenizer.texts_to_sequences([start_token])[0]\n",
        "\n",
        "    output = []\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        # Prepare decoder input for the current step\n",
        "        decoder_input_for_prediction = pad_sequences([target_seq], maxlen=max_headline_len, padding='post')\n",
        "\n",
        "        # Predict next token probabilities\n",
        "        predictions = model.predict([encoded_input_seq, decoder_input_for_prediction], verbose=0)\n",
        "\n",
        "\n",
        "        # Apply temperature scaling to adjust the randomness\n",
        "        predictions = np.squeeze(predictions, axis=0)[-1, :] / temperature # Get predictions for the last time step\n",
        "        predictions = np.exp(predictions) / np.sum(np.exp(predictions))  # Softmax function\n",
        "\n",
        "        # Top-k sampling: choose the top k predictions\n",
        "        top_indices = predictions.argsort()[-top_k:][::-1]\n",
        "        sampled_token_index = np.random.choice(top_indices, p=predictions[top_indices] / np.sum(predictions[top_indices]))\n",
        "\n",
        "        # Convert the sampled token to a word\n",
        "        sampled_word = tokenizer.index_word.get(sampled_token_index, '')\n",
        "\n",
        "        if sampled_word == end_token or sampled_word == '':\n",
        "            break\n",
        "\n",
        "        output.append(sampled_word)\n",
        "        target_seq.append(sampled_token_index)\n",
        "\n",
        "\n",
        "    return ' '.join(output)\n",
        "\n",
        "# Test the model on unseen paragraphs\n",
        "for i in range(5):\n",
        "    test_text = news_df['clean_text'].iloc[i + 1]\n",
        "    print(f\"Input Text: {test_text}\")\n",
        "    lstm_headline = decode_sequence(lstm_model, test_text, headline_tokenizer, max_headline_len)\n",
        "    gru_headline = decode_sequence(gru_model, test_text, headline_tokenizer, max_headline_len)\n",
        "\n",
        "    print(f\"LSTM Headline: {lstm_headline}\")\n",
        "    print(f\"GRU Headline: {gru_headline}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "üìÑ LSTM vs GRU ‚Äì Performance Comparison Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sections to cover:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| Criteria                   | LSTM                                 | GRU                            |\n",
        "| -------------------------- | ------------------------------------ | ------------------------------ |\n",
        "| Architecture               | Uses 3 gates (input, forget, output) | Uses 2 gates (reset, update)   |\n",
        "| Training Time              | Slightly longer                      | Faster due to fewer parameters |\n",
        "| Accuracy (Validation Loss) | Example: 0.47                        | Example: 0.45                  |\n",
        "| Output Quality (Argmax)    | Good, sometimes more formal          | Often more concise             |\n",
        "| Output Quality (Top-K)     | Slightly repetitive                  | More creative and readable     |\n",
        "| Model Size                 | \\~5.6 MB                             | \\~4.8 MB                       |\n",
        "| Ideal For                  | Long-sequence learning               | Faster training on short text  |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conclusion:\n",
        "\n",
        "Both models perform well, but GRU provides comparable accuracy with faster training and smaller size, making it a good choice for real-time applications. LSTM, however, may capture complex dependencies better in longer contexts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bonus Summary: Headline Decoding Techniques\n",
        "\n",
        "\n",
        "In this bonus section, we replaced the traditional argmax decoding strategy with two advanced\n",
        "methods: Top-K Sampling and Beam Search. These techniques improve the diversity and quality of\n",
        "generated headlines.\n",
        "1. Argmax (Greedy Decoding):\n",
        "Selects the most probable word at each time step. Fast and deterministic but may miss better\n",
        "long-term sequences.\n",
        "2. Top-K Sampling:\n",
        "Samples randomly from the top K highest probability words. Introduces diversity and creativity in the\n",
        "output.\n",
        "3. Beam Search:\n",
        "Explores multiple possible sequences by keeping the top N candidates (beam width). Improves\n",
        "output quality and handles context better than argmax"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
